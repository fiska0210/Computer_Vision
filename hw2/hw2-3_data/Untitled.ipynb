{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs():\n",
    "    \n",
    "    train_x=[]\n",
    "    train_y=[]\n",
    "    for category in os.listdir('./train'):\n",
    "            print ('loading category {}...'.format(category))\n",
    "            label = category[-1]\n",
    "            for image in os.listdir('./train/' + category):\n",
    "                f = ('./train/' + category + '/' + image)\n",
    "                train_x.append(cv2.imread(f, 0))\n",
    "                train_y.append(label)\n",
    "                \n",
    "    train_x=np.array(train_x,dtype=np.float32)\n",
    "    train_x=train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "    train_x/=255\n",
    "    train_y=np.array(train_y,dtype=np.float32)\n",
    "    \n",
    "    val_x=[]\n",
    "    val_y=[]\n",
    "    for category in os.listdir('./valid'):\n",
    "            label = category[-1]\n",
    "            for image in os.listdir('./valid/' + category):\n",
    "                f = ('./valid/' + category + '/' + image)\n",
    "                val_x.append(cv2.imread(f,0))\n",
    "                val_y.append(label)\n",
    "                   \n",
    "    val_x=np.array(train_x,dtype=np.float32)\n",
    "    val_x=train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "    val_x/=255\n",
    "    val_y=np.array(train_y,dtype=np.float32)\n",
    "    \n",
    "    return train_x,train_y,val_x,val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading category class_8...\n",
      "loading category class_9...\n",
      "loading category class_2...\n",
      "loading category class_0...\n",
      "loading category class_4...\n",
      "loading category class_3...\n",
      "loading category class_1...\n",
      "loading category class_5...\n",
      "loading category class_6...\n",
      "loading category class_7...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x,train_y,val_x,val_y = load_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = (train_x,train_y),(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import os\n",
    "import argparse\n",
    "import keras\n",
    "\n",
    "from keras.models               import Sequential, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers           import Adam, Adadelta\n",
    "from keras.utils                import np_utils\n",
    "from keras                      import regularizers\n",
    "from keras.preprocessing.image  import ImageDataGenerator\n",
    "from keras.layers               import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers               import Convolution2D, Conv2D, AveragePooling2D\n",
    "from keras.layers               import ZeroPadding2D, MaxPooling2D\n",
    "from keras.callbacks            import ModelCheckpoint,EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print (x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.3456 - acc: 0.8950Epoch 00001: val_acc improved from -inf to 0.97660, saving model to save/Model.01-0.9766.hdf5\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.3452 - acc: 0.8951 - val_loss: 0.0792 - val_acc: 0.9766\n",
      "Epoch 2/12\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9661Epoch 00002: val_acc improved from 0.97660 to 0.98340, saving model to save/Model.02-0.9834.hdf5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1150 - acc: 0.9661 - val_loss: 0.0559 - val_acc: 0.9834\n",
      "Epoch 3/12\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9745Epoch 00003: val_acc improved from 0.98340 to 0.98610, saving model to save/Model.03-0.9861.hdf5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0856 - acc: 0.9745 - val_loss: 0.0421 - val_acc: 0.9861\n",
      "Epoch 4/12\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9788Epoch 00004: val_acc improved from 0.98610 to 0.98850, saving model to save/Model.04-0.9885.hdf5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0710 - acc: 0.9788 - val_loss: 0.0384 - val_acc: 0.9885\n",
      "Epoch 5/12\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9813Epoch 00005: val_acc did not improve\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0630 - acc: 0.9814 - val_loss: 0.0367 - val_acc: 0.9880\n",
      "Epoch 6/12\n",
      "59136/60000 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9830Epoch 00006: val_acc did not improve\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0566 - acc: 0.9830 - val_loss: 0.0338 - val_acc: 0.9885\n",
      "Epoch 7/12\n",
      "59264/60000 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9852Epoch 00007: val_acc improved from 0.98850 to 0.99050, saving model to save/Model.07-0.9905.hdf5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0504 - acc: 0.9851 - val_loss: 0.0304 - val_acc: 0.9905\n",
      "Epoch 8/12\n",
      "59136/60000 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9859Epoch 00008: val_acc improved from 0.99050 to 0.99090, saving model to save/Model.08-0.9909.hdf5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0473 - acc: 0.9858 - val_loss: 0.0287 - val_acc: 0.9909\n",
      "Epoch 9/12\n",
      "59136/60000 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9871Epoch 00009: val_acc did not improve\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0429 - acc: 0.9872 - val_loss: 0.0311 - val_acc: 0.9901\n",
      "Epoch 10/12\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9875Epoch 00010: val_acc did not improve\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0405 - acc: 0.9875 - val_loss: 0.0279 - val_acc: 0.9907\n",
      "Epoch 11/12\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9881Epoch 00011: val_acc did not improve\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0385 - acc: 0.9882 - val_loss: 0.0282 - val_acc: 0.9901\n",
      "Epoch 12/12\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9888Epoch 00012: val_acc did not improve\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0376 - acc: 0.9888 - val_loss: 0.0300 - val_acc: 0.9905\n",
      "10000/10000 [==============================] - 1s 79us/step\n",
      "Test loss: 0.030049870482723055\n",
      "Test accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print (x_train.shape)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "filepath='save/Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), \n",
    "         callbacks=callbacks_list)\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
