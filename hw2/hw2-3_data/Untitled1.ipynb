{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1)\n",
      "1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1259: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:2880: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdb\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Model,load_model\n",
    "import cv2\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def load_imgs(base_dir):\n",
    "    train_base_dir=os.path.join(base_dir,'train')\n",
    "    train_data_dir=[os.path.join(train_base_dir,'class_{}'.format(i)) for i in range(10)]\n",
    "\n",
    "    valid_base_dir=os.path.join(base_dir,'valid')\n",
    "    valid_data_dir=[os.path.join(valid_base_dir,'class_{}'.format(i)) for i in range(10)]\n",
    "\n",
    "    train_img_files=[]\n",
    "    train_x=[]\n",
    "    train_y=[]\n",
    "    for i,train_dir in enumerate(train_data_dir):\n",
    "        train_img_files=train_img_files+[os.path.join(train_dir,f) for f in os.listdir(train_dir) if (f[-4:]=='.png')]\n",
    "        train_y=train_y+[i for f in os.listdir(train_dir) if (f[-4:]=='.png')]\n",
    "\n",
    "    train_x=[cv2.imread(f,0) for f in train_img_files]\n",
    "    train_x=np.array(train_x,dtype=np.float32)\n",
    "    train_x=train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "    train_x/=255\n",
    "\n",
    "\n",
    "    val_img_files=[]\n",
    "    val_x=[]\n",
    "    val_y=[]\n",
    "    for i,valid_dir in enumerate(valid_data_dir):\n",
    "        val_img_files=val_img_files+[os.path.join(valid_dir,f) for i,f in enumerate(os.listdir(valid_dir)) if (f[-4:]=='.png' and i<100)]\n",
    "        val_y=val_y+[i for j,f in enumerate(os.listdir(valid_dir)) if (f[-4:]=='.png' and j<100)]\n",
    "    val_x=[cv2.imread(f,0) for f in val_img_files]\n",
    "    val_x=np.array(val_x,dtype=np.float32)\n",
    "    val_x=val_x.reshape(val_x.shape[0],val_x.shape[1],val_x.shape[2],1)\n",
    "    val_x/=255\n",
    "    return train_x,train_y,val_x,val_y\n",
    "\n",
    "base_dir='./'\n",
    "train_x,train_y,val_x,val_y=load_imgs(base_dir)\n",
    "del train_x, train_y\n",
    "print (val_x.shape)\n",
    "print (len(val_y))\n",
    "\n",
    "layer_name='dense_4'\n",
    "\n",
    "model=load_model('save/Model.08-0.9909.hdf5')\n",
    "model.summary()\n",
    "#pdb.set_trace()\n",
    "intermediate_layer_model=Model(inputs=model.input,outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output=intermediate_layer_model.predict(val_x)\n",
    "intermediate_output=intermediate_output.reshape(intermediate_output.shape[0],-1)\n",
    "print (intermediate_output.shape)\n",
    "\n",
    "embedded=TSNE(n_components=2).fit_transform(intermediate_output)\n",
    "print (embedded.shape)\n",
    "\n",
    "color=['b','g','r','c','m','y','k','burlywood','chartreuse','gray']\n",
    "#pdb.set_trace()\n",
    "#for i in range(10):\n",
    "for i in range(embedded.shape[0]):\n",
    "    plt.plot(embedded[i,0],embedded[i,1],color=color[val_y[i]],marker='o')\n",
    "plt.savefig('{}_tsne.png'.format(layer_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
